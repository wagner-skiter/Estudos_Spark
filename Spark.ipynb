{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "turned-affiliation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\opt\\\\spark\\\\spark-3.1.1-bin-hadoop2.7'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "findspark.find()\n",
    "import pyspark\n",
    "findspark.find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "mounted-indie",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "conf = pyspark.SparkConf().setAppName('SparkApp').setMaster('local')\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sacred-private",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'pyspark' from 'C:\\\\opt\\\\spark\\\\spark-3.1.1-bin-hadoop2.7\\\\python\\\\pyspark\\\\__init__.py'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dental-juice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testando o Spark e criando uma RDD\n",
    "\n",
    "lst = [25, 90, 81, 37, 776, 3320]\n",
    "testdata = sc.parallelize(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "religious-particular",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumSlices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Distribute a local Python collection to form an RDD. Using range\n",
       "is recommended if the input represents a range for performance.\n",
       "\n",
       "Examples\n",
       "--------\n",
       ">>> sc.parallelize([0, 2, 3, 4, 6], 5).glom().collect()\n",
       "[[0], [2], [3], [4], [6]]\n",
       ">>> sc.parallelize(range(0, 6, 2), 5).glom().collect()\n",
       "[[], [0], [], [2], [4]]\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\opt\\spark\\spark-3.1.1-bin-hadoop2.7\\python\\pyspark\\context.py\n",
       "\u001b[1;31mType:\u001b[0m      method\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?sc.parallelize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "protective-nirvana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "instrumental-strain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "korean-values",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[25, 90, 81, 37, 776, 3320]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latter-village",
   "metadata": {},
   "source": [
    "**RDD's são coleçães distribuídas de itens. RDD's podem ser criadas a partir do Hadoop (Arquivos no HDFS), através da transformação de outras RDD's a partir de bancos de dados(relacionais e não-relacionais) ou a partir de arquivos locais.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "coastal-drink",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando uma RDD a partir de um arquivo csv\n",
    "\n",
    "sentimentoRDD = sc.textFile('sentimentos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "twenty-little",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sentimentoRDD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "considerable-replica",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ação - contando o número de registros\n",
    "\n",
    "sentimentoRDD.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "increased-idaho",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positivo,Esse livro é incrível.',\n",
       " 'positivo,Um dos melhores livros que eu já li.',\n",
       " 'positivo,um dos melhores livros que eu já li',\n",
       " 'positivo,Acho que ele tem um conteúdo que vai além do que está em sua descrição.',\n",
       " 'positivo,O Sol é para todos é profundo e emocionante']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # listando os 5 primeiros registros\n",
    "\n",
    "sentimentoRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "vietnamese-person",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['POSITIVO,ESSE LIVRO É INCRÍVEL.',\n",
       " 'POSITIVO,UM DOS MELHORES LIVROS QUE EU JÁ LI.',\n",
       " 'POSITIVO,UM DOS MELHORES LIVROS QUE EU JÁ LI',\n",
       " 'POSITIVO,ACHO QUE ELE TEM UM CONTEÚDO QUE VAI ALÉM DO QUE ESTÁ EM SUA DESCRIÇÃO.',\n",
       " 'POSITIVO,O SOL É PARA TODOS É PROFUNDO E EMOCIONANTE']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transformando os dados - transformação letras maiúsculas\n",
    "\n",
    "transfRDD = sentimentoRDD.map(lambda x: x.upper())\n",
    "transfRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "moved-siemens",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positivo,Esse livro é incrível.',\n",
       " 'positivo,Um dos melhores livros que eu já li.',\n",
       " 'positivo,um dos melhores livros que eu já li',\n",
       " 'positivo,Acho que ele tem um conteúdo que vai além do que está em sua descrição.',\n",
       " 'positivo,O Sol é para todos é profundo e emocionante']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentimentoRDD.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "catholic-tolerance",
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo = sc.textFile('sentimentos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fluid-comparison",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(arquivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "threatened-recognition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arquivo.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "floral-rehabilitation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'positivo,Esse livro é incrível.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arquivo.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "healthy-elimination",
   "metadata": {},
   "outputs": [],
   "source": [
    "linhasComSol = arquivo.filter(lambda line:'Sol' in line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "nearby-royal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(linhasComSol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "acting-header",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linhasComSol.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "middle-bidding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['positivo,O Sol é para todos é profundo e emocionante',\n",
       " 'negativo,Sol para todos é um Livro ruim',\n",
       " 'negativo,O Sol para todos não é para todos.']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linhasComSol.take(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-logan",
   "metadata": {},
   "source": [
    "Primeiro a função **map()** determina o comprimento de cada linha do arquivo, criando uma RDD. A função **reduce()** é chamada para encontar a linha com maior número de caracteres. o argumento para as funções **map() e reduce()** são funções anônimas criadas com lambda(da linguagem Python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "based-tension",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arquivo.map(lambda line: len(line.split())).reduce(lambda a, b: a if (a > b) else b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hispanic-cemetery",
   "metadata": {},
   "source": [
    "Esta linha pode ser reescrita da seguinte forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "elementary-posting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def max(a, b):\n",
    "    if a > b:\n",
    "        return a\n",
    "    else:\n",
    "        return b\n",
    "\n",
    "arquivo.map(lambda line: len(line.split())).reduce(max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-density",
   "metadata": {},
   "source": [
    "## Operação de MapReduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "preliminary-turtle",
   "metadata": {},
   "source": [
    "As operações de MapReduce foram popularizadas pelo hadoop e podem ser feitas com Spark até 100x mais rápiado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "mediterranean-married",
   "metadata": {},
   "outputs": [],
   "source": [
    "contaPalavras = arquivo.flatMap(lambda line : linesplit()).map(lambda palavra: (palavra, 1)).reduceByKey(lambda a, b:a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "played-pennsylvania",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[20] at RDD at PythonRDD.scala:53"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contaPalavras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powerful-thomson",
   "metadata": {},
   "source": [
    "http://localhost:4040/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
